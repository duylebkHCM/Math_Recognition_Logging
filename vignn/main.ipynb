{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.data import metrics \n",
    "from nltk.metrics.distance import edit_distance\n",
    "from data import build_vocab\n",
    "from modules.converter import builder\n",
    "from utils.predict_utils import resize\n",
    "from utils.data_utils import post_process\n",
    "from infer import prepare_model\n",
    "from PIL import Image\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/media/huynhtruc0309/DATA/Math_Expression/my_source/Math_Recognition/config/test/cviu_experiments/ViGNN/experiment_0602.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(config_path), Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problem': 'math_recognition', 'imgH': None, 'imgW': None, 'max_width': 800, 'max_height': 800, 'min_width': 32, 'min_height': 32, 'batch_max_length': 500, 'rgb': False, 'pad': False, 'mean': 0.5, 'std': 0.5, 'beam_size': 1, 'vocab': '../data_20211227/vocab.txt', 'character': [], 'num_gpu': 0, 'batch_size': 0, 'workers': 0, 'postprocess': False, 'Transformation': 'None', 'FeatureExtraction': {'name': 'None'}, 'SequenceModeling': {'name': 'ViG', 'params': {'backbone': {'name': 'resnet', 'input_channel': 1, 'output_channel': 512, 'gcb': False}, 'input_channel': 1}}, 'Prediction': {'name': 'Attnv2', 'params': {'seqmodel': 'VIG', 'input_size': 256, 'hidden_size': 256, 'kernel_size': 2, 'kernel_dim': 128, 'embed_target': True, 'enc_init': True, 'attn_type': 'coverage', 'method': 'concat', 'teacher_forcing': 1.0, 'droprate': 0.25}}, 'export_csv': False, 'sanity_check': False, 'manualSeed': 1111, 'saved_model': '/media/huynhtruc0309/DATA/Math_Expression/my_source/Math_Recognition/saved_models/math_recognition/cviu_experiment/ViGNN/experiment_0602/best_ckpt_accuracy.pth'}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['vocab'] = '/media/huynhtruc0309/DATA/Math_Expression/my_source/data_20211227/vocab.txt'\n",
    "config['device'] = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = build_vocab.build_tokenizer(config)\n",
    "converter = builder.create_converter(config)\n",
    "config['num_class'] = len(converter.character)\n",
    "config['viz_attn'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499\n"
     ]
    }
   ],
   "source": [
    "print(config['num_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = '/media/huynhtruc0309/DATA/Math_Expression/my_source/data_20211115/updated_22011227/im2latex_validate_filter_updated_20220216.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(val_dir, sep=',', keep_default_na=False, names=['id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id                                              label\n",
      "0  5abbb9b19f.png  \\int _ { - \\epsilon } ^ { \\infty } d l \\: \\mat...\n",
      "1  329a44c373.png  [ { \\bar { K } } _ { a } ^ { - } ( p ) , { \\ba...\n"
     ]
    }
   ],
   "source": [
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/media/huynhtruc0309/DATA/Math_Expression/my_source/data_20211115/formula_images_processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8370\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = r'\\int _ { - \\epsilon } ^ { \\infty } d l \\: \\mathrm { e } ^ { - l \\zeta } \\int _ { - \\epsilon } ^ { \\infty } d l ^ { \\prime } \\mathrm { e } ^ { - l ^ { \\prime } \\zeta } l l ^ { \\prime } { \\frac { l ^ { \\prime } - l } { l + l ^ { \\prime } } } \\{ 3 \\, \\delta ^ { \\prime \\prime } ( l ) - { \\frac { 3 } { 4 } } t \\, \\delta ( l ) \\} = 0 .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['eval_data'] = data_dir\n",
    "config['use_resizer'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDatasetSingle(Dataset):\n",
    "    def __init__(self, df, opt, start_idx=0, has_label=False):\n",
    "        test_df = df.copy()\n",
    "        test_df = test_df.iloc[start_idx:]\n",
    "        test_df.reset_index(drop=True, inplace=True)\n",
    "        self.df = test_df\n",
    "        self.opt = opt\n",
    "        self.has_label=has_label\n",
    "        self.resizer = None\n",
    "        self.preprocess_time = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx == len(self):\n",
    "            return None, None, None \n",
    "        \n",
    "        if self.has_label:\n",
    "            img_name, label = self.df.loc[idx, 'id'], self.df.loc[idx, 'label']\n",
    "            if len(label):\n",
    "                if self.opt.get('token_level', 'word') == 'word':\n",
    "                    label = [str(label).strip().split()]\n",
    "                else: label = [str(label)]\n",
    "        else:\n",
    "            img_name = self.df.loc[idx, 'id']\n",
    "        \n",
    "        img_path=os.path.join(self.opt['eval_data'], str(img_name))\n",
    "        start_time = time.time()\n",
    "        new_img = resize(self.resizer, img_path, self.opt)\n",
    "        end_time = time.time()\n",
    "        pre_time = end_time - start_time\n",
    "        self.preprocess_time += pre_time\n",
    "\n",
    "        if self.has_label:\n",
    "            return new_img, label, [img_name]\n",
    "        else:\n",
    "            return new_img, [img_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id                                              label\n",
      "0  5abbb9b19f.png  \\int _ { - \\epsilon } ^ { \\infty } d l \\: \\mat...\n",
      "1  329a44c373.png  [ { \\bar { K } } _ { a } ^ { - } ( p ) , { \\ba...\n",
      "2  73b51f198b.png  E ( v ) = \\frac { d } { d t } E ( q ) \\; \\; \\;...\n"
     ]
    }
   ],
   "source": [
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TestDatasetSingle(df, config, start_idx=0, has_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Transformation module specified\n",
      "------------ Options -------------\n",
      "problem: math_recognition\n",
      "imgH: None\n",
      "imgW: None\n",
      "max_width: 800\n",
      "max_height: 800\n",
      "min_width: 32\n",
      "min_height: 32\n",
      "batch_max_length: 500\n",
      "rgb: False\n",
      "pad: False\n",
      "mean: 0.5\n",
      "std: 0.5\n",
      "beam_size: 1\n",
      "vocab: /media/huynhtruc0309/DATA/Math_Expression/my_source/data_20211227/vocab.txt\n",
      "character: ['}', '{', '_', '^', '2', '(', ')', '=', '1', '-', ',', '\\\\frac', '+', 'i', '0', 'x', 'n', '.', '\\\\,', 'd', 'a', '\\\\mu', 'e', 'k', 'm', 'r', 'c', 'p', '\\\\partial', '\\\\alpha', 't', 'A', '~', '\\\\;', '3', 'j', 's', 'l', '\\\\left(', '\\\\right)', 'g', '4', '\\\\', '\\\\nu', '\\\\prime', '\\\\pi', 'z', 'b', '\\\\phi', '|', '\\\\mathrm', '\\\\cal', '\\\\delta', 'f', 'N', 'q', '\\\\lambda', 'T', 'S', '\\\\beta', ']', 'R', '[', '\\\\bar', '\\\\int', 'D', 'M', 'L', '\\\\operatorname', 'B', 'F', '\\\\sigma', 'y', '&', '\\\\\\\\', '\\\\theta', '\\\\gamma', '\\\\psi', 'h', '/', '\\\\hat', '\\\\sqrt', 'H', '\\\\sum', 'u', '\\\\tilde', '\\\\rho', 'o', '\\\\tau', 'C', 'G', 'P', 'V', 'I', 'E', '\\\\omega', 'X', '\\\\epsilon', 'J', '\\\\bf', '\\\\eta', 'Q', '\\\\Phi', '\\\\xi', 'v', '\\\\quad', '\\\\vec', '\\\\Gamma', 'K', '\\\\infty', '5', '\\\\right]', '\\\\left[', 'U', '\\\\Lambda', '\\\\pm', '\\\\dot', 'W', 'Z', '\\\\begin{array}', '\\\\end{array}', '\\\\varphi', '*', '\\\\Delta', '\\\\rangle', '6', 'w', '\\\\chi', '\\\\Omega', ';', '\\\\kappa', '\\\\qquad', '\\\\}', '\\\\{', '\\\\Psi', '\\\\equiv', '8', '\\\\cdot', '\\\\overline', '\\\\!', '\\\\langle', '\\\\rightarrow', '>', '\\\\dagger', '\\\\varepsilon', '\\\\zeta', '\\\\nabla', '<', 'O', 'Y', ':', '\\\\Sigma', '\\\\cdots', '\\\\mathcal', '\\\\ldots', '\\\\ell', '\\\\left\\\\{', '\\\\:', '\\\\sim', '\\\\otimes', '\\\\wedge', '\\\\Pi', '!', '\\\\operatorname*', '7', '\\\\prod', '\\\\hspace', '\\\\hbar', '\\\\in', '\\\\vert', '9', '\\\\widetilde', '\\\\right\\\\}', '\\\\to', '\\\\Big', '\\\\Theta', '\\\\mid', '\\\\times', '\\\\right|', '\\\\mathbf', '\\\\underline', '\\\\ast', '\\\\dots', '\\\\leq', '\\\\left|', '\\\\approx', '\\\\star', '\\\\widehat', '\\\\stackrel', '\\\\right.', '\\\\displaystyle', '\\\\big', '\\\\perp', '\\\\left.', '\\\\geq', '\\\\mp', '\\\\simeq', '\\\\dag', '\\\\vartheta', '\\\\Bigr', '\\\\right\\\\rangle', \"'\", '\\\\neq', '\\\\Bigl', '\\\\circ', '\\\\longrightarrow', '\\\\oint', '\\\\biggl', '\\\\biggr', '\\\\bigg', '\\\\textstyle', '\\\\ddot', '\\\\left\\\\langle', '\\\\not', '\\\\bigl', '\\\\oplus', '\\\\bigr', '\\\\boldmath', '\\\\Xi', '\\\\propto', '\\\\check', '\\\\nonumber', '\\\\triangle', '\\\\le', '\\\\varrho', '\\\\ge', '\\\\forall', '\\\\scriptscriptstyle', '\\\\imath', '\\\\right>', '\\\\|', '--', '\\\\lbrack', '\\\\sp', '\\\\bot', '\\\\it', '\\\\leftrightarrow', '\\\\Rightarrow', '\\\\parallel', '\\\\mapsto', '\\\\subset', '\\\\textrm', '\\\\iota', '\\\\l', '\\\\scriptsize', '\\\\Bigg', '\\\\left<', '\\\\binom', '\\\\overrightarrow', '\\\\ll', '\\\\jmath', '\\\\phantom', '\\\\sf', '\\\\cong', '\\\\tiny', '\\\\ne', '\\\\gg', '\\\\Biggr', '\\\\d', '\\\\Biggl', '\\\\o', '\\\\Upsilon', '\\\\breve', '\\\\L', '\\\\vee', '\\\\bigoplus', '\\\\bullet', '\\\\small', '\\\\wp', '\\\\scriptstyle', '\\\\atop', '\\\\varpi', '\\\\downarrow', '\\\\kern', '\\\\#', '\\\\vdots', '\\\\uparrow', '\\\\cap', '\\\\rbrack', '\\\\Im', '\\\\supset', '\\\\sb', '\\\\slash', '\\\\hline', '\\\\cup', '\\\\Re', '\\\\Longrightarrow', '\\\\mit', '\\\\upsilon', '\\\\underbrace', '\\\\acute', '\\\\varsigma', '\\\\lbrace', '\\\\protect', '\\\\rbrace', '\\\\O', '\\\\vspace', '\\\\bigtriangleup', '\\\\Leftrightarrow', '\\\\S', '\\\\mathsf', '`', '\\\\longleftrightarrow', '\\\\i', '\\\\leftarrow', '\\\\Vert', '\\\\footnotesize', '\\\\ddots', '\\\\rightharpoonup', '\\\\Large', '\\\\Longleftrightarrow', '\\\\enspace', '\\\\right\\\\vert', 'mm', '\\\\left\\\\vert', '\\\\raisebox', '\\\\cdotp', 'ule', '\\\\bigotimes', '\\\\put', '\\\\makebox', '\\\\tt', '\\\\emptyset', '\\\\doteq', '\\\\hfill', '\\\\P', '\\\\overleftarrow', '\\\\large', '\\\\left\\\\|', '\\\\right\\\\|', '\\\\textbf', '\\\\mathop', '\\\\vphantom', '\\\\llap', '\\\\backslash', '\"', '\\\\sharp', '\\\\buildrel', '\\\\raise', '\\\\sl', '\\\\flat', '\\\\ref', '\\\\odot', '\\\\noalign', '\\\\mathit', '\\\\label', '\\\\textup', 'cm', '\\\\bigcup', '\\\\strut', '\\\\/', '\\\\longmapsto', '\\\\rfloor', '\\\\unitlength', '\\\\overbrace', '\\\\thinspace', '\\\\colon', '\\\\subseteq', '\\\\setlength', '\\\\ni', '\\\\pounds', '\\\\diamond', '\\\\_', '\\\\fbox', '\\\\ominus', '\\\\line', '\\\\enskip', '[object', 'Object]', '\\\\bigwedge', '\\\\aleph', '\\\\circle', '?', '\\\\bigtriangledown', '\\\\lfloor', '\\\\bigcap', '\\\\vrule', '\\\\smallskip', '\\\\b', '\\\\land', '\\\\bmod', '\\\\space', '\\\\left\\\\lbrack', '\\\\right\\\\rbrack', '\\\\vskip', '\\\\hookrightarrow', '\\\\rlap', '\\\\diamondsuit', '\\\\hrule', '\\\\natural', '\\\\pmod', '\\\\setminus', '\\\\ddagger', '\\\\vline', '\\\\textit', '\\\\-', '\\\\texttt', '\\\\lower', '\\\\longleftarrow', '\\\\c', 'pt', '\\\\right\\\\rfloor', '\\\\left\\\\lbrace', '\\\\right\\\\rbrace', '\\\\relax', '\\\\&', '\\\\normalsize', '\\\\bigm', '\\\\thicklines', '0.14', '8.5', '\\\\framebox', '\\\\sc', '\\\\hfil', '\\\\top', '0.4', '\\\\vdash', '\\\\j', '\\\\textsf', '\\\\mkern', '\\\\textnormal', '\\\\supseteq', '\\\\medskip', '\\\\exists', '\\\\smash', '\\\\surd', '\\\\m', '\\\\Biggm', '\\\\sqcup', '\\\\null', '\\\\special', '0.1', '\\\\itshape', '\\\\lceil', '\\\\do', '\\\\lefteqn', '\\\\Huge', '---', '\\\\renewcommand', '\\\\arraystretch', '\\\\unboldmath', '\\\\prec', '\\\\LARGE', '\\\\cite', '\\\\Longleftarrow', '\\\\triangleright', '\\\\ss', '\\\\ensuremath', '\\\\amalg', '\\\\rightleftharpoons', '\\\\grave', \"\\\\'\", '\\\\hphantom', '\\\\protectu', '\\\\asymp', '\\\\oslash', '\\\\setcounter', '\\\\smile', '\\\\ae', '\\\\arraycolsep', '\\\\vcenter', '\\\\Bigm', '\\\\ooalign', '\\\\crcr', '\\\\skew', '\\\\*', '0.5', '\\\\AA', '\\\\sqcap', '\\\\vss', '\\\\mathbin', '\\\\left\\\\lfloor', '\\\\em', '\\\\succeq', '\\\\bigsqcup', '\\\\lq', '\\\\nolinebreak', '\\\\multicolumn', '\\\\parbox', '\\\\multiput', '\\\\SS', '\\\\notin', '\\\\fboxsep', '\\\\mathversion', '\\\\ddag', '\\\\lgroup', '\\\\rgroup', '\\\\arrowvert', '\\\\mathrel', '3.1', '3.2', '\\\\Downarrow', '\\\\smallint', '\\\\mskip', 'in', '\\\\hss']\n",
      "num_gpu: 0\n",
      "batch_size: 0\n",
      "workers: 0\n",
      "postprocess: False\n",
      "Transformation: None\n",
      "FeatureExtraction: {'name': 'None'}\n",
      "SequenceModeling: {'name': 'ViG', 'params': {'backbone': {'name': 'resnet', 'input_channel': 1, 'output_channel': 512, 'gcb': False}, 'input_channel': 1}}\n",
      "Prediction: {'name': 'Attnv2', 'params': {'seqmodel': 'VIG', 'input_size': 256, 'hidden_size': 256, 'kernel_size': 2, 'kernel_dim': 128, 'embed_target': True, 'enc_init': True, 'attn_type': 'coverage', 'method': 'concat', 'teacher_forcing': 1.0, 'droprate': 0.25, 'num_classes': 499, 'device': 'cpu'}}\n",
      "export_csv: False\n",
      "sanity_check: False\n",
      "manualSeed: 1111\n",
      "saved_model: /media/huynhtruc0309/DATA/Math_Expression/my_source/Math_Recognition/saved_models/math_recognition/cviu_experiment/ViGNN/experiment_0602/best_ckpt_accuracy.pth\n",
      "device: cpu\n",
      "num_class: 499\n",
      "viz_attn: False\n",
      "eval_data: /media/huynhtruc0309/DATA/Math_Expression/my_source/data_20211115/formula_images_processed\n",
      "use_resizer: False\n",
      "---------------------------------------\n",
      "\n",
      "loading pretrained model from /media/huynhtruc0309/DATA/Math_Expression/my_source/Math_Recognition/saved_models/math_recognition/cviu_experiment/ViGNN/experiment_0602/best_ckpt_accuracy.pth\n"
     ]
    }
   ],
   "source": [
    "model = prepare_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.interpretation.vit_visualize import show_mask_on_image, get_saliency_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_Saver:\n",
    "    def __init__(self, img_path, output_dir):\n",
    "        self.img_path = img_path\n",
    "        self.output_dir = output_dir\n",
    "        self.down_sample = 1\n",
    "\n",
    "    def __call__(self, save_name, save_obj):\n",
    "        image = Image.open(self.img_path).convert('RGB')\n",
    "        w, h = image.size\n",
    "        new_h = int(h / self.down_sample)\n",
    "        new_w = int(w / self.down_sample)\n",
    "        \n",
    "        if self.down_sample > 1:\n",
    "            image = image.resize((new_w, new_h), Image.LANCZOS)\n",
    "        else:\n",
    "            image = image.resize((new_w, new_h), Image.BICUBIC)\n",
    "\n",
    "        np_img = np.asarray(image).astype('uint8')\n",
    "        \n",
    "        resize_mask = F.interpolate(save_obj, (np_img.shape[0], np_img.shape[1]), mode='bicubic', align_corners=True)\n",
    "        resize_mask = resize_mask.squeeze(0).squeeze(0)\n",
    "        resize_mask =  np.asarray(resize_mask).astype(float)\n",
    "        resize_mask = get_saliency_map(np_img, resize_mask)\n",
    "\n",
    "        save_path = os.path.join(self.output_dir, os.path.basename(self.img_path).split('.')[0])\n",
    "        if not os.path.exists(save_path): os.mkdir(save_path)\n",
    "        cv2.imwrite(os.path.join(save_path, save_name), resize_mask)\n",
    "        if not os.path.exists(os.path.join(save_path, os.path.basename(self.img_path))):\n",
    "            image.save(os.path.join(save_path, os.path.basename(self.img_path)), format='PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/media/huynhtruc0309/DATA/Math_Expression/my_source/Math_Recognition/analysis/cviu_analysis/model_analysis/vignn/experiment_2302'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_act_info(model, dataset, output_dir, num_process=1):\n",
    "    logging.basicConfig(filename=os.path.join(output_dir, 'forward_logger.txt'),\n",
    "                    filemode='w',\n",
    "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    force=True\n",
    "    )\n",
    "\n",
    "    forward_logger = logging.getLogger(name='Logger')\n",
    "\n",
    "    model.eval()\n",
    "    for idx, (image_tensors, _, img_name) in enumerate(dataset):\n",
    "        if idx == num_process:\n",
    "            break\n",
    "\n",
    "        if image_tensors is None:\n",
    "            break\n",
    "\n",
    "        forward_logger.info(f'----------{img_name[0]}-----------')\n",
    "        with torch.no_grad():\n",
    "            image_tensors = image_tensors.to(config['device'])\n",
    "            if not os.path.exists(os.path.join(output_dir, 'viz_output')): os.mkdir(os.path.join(output_dir, 'viz_output'))\n",
    "            attnmap_viz = {\n",
    "                'obj': Activation_Saver(\n",
    "                    os.path.join(data_dir, img_name[0]), \n",
    "                    os.path.join(output_dir, 'viz_output')\n",
    "                )\n",
    "            }\n",
    "            context_values, output_shapes = model.forward_encoder(image_tensors, debug=True, logger=forward_logger, attnmap_viz=attnmap_viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_process=5\n",
    "get_act_info(model, dataset, output_dir, num_process=num_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('textrecog_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f1b9a3d6cef30d75f8aab729417ba1402a735fb36cc944531c9997492615222"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
